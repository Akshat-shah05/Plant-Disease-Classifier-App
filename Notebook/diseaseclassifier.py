# -*- coding: utf-8 -*-
"""DiseaseClassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wG4AT0jVmOCehO9uZoNih2v61kN6Cp6I

# Plant Disease Predictor Using CNN's - Image Classification

## Seeding for Reproducibility of Results
"""

# Setting the seeds for reproducibility
# Internally some random process happens (e.g if we're building a neural network and it trains)
# Each time you run the code it might give slightly different results
# Thus we set a seed to prevent this --> consistent results
import random
random.seed(0)

import numpy as np
np.random.seed(0)

import tensorflow as tf
tf.random.set_seed(0)

"""## Install other Dependencies"""

import os
import json
from zipfile import ZipFile
from PIL import Image

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models

"""## Data Curation from Kaggle"""

!pip install kaggle

# Set up environemtn variables
kaggle_credentials = json.load(open("kaggle.json"))
os.environ['KAGGLE_USERNAME'] = kaggle_credentials['username']
os.environ['KAGGLE_KEY'] = kaggle_credentials['key']

!kaggle datasets download -d abdallahalidev/plantvillage-dataset

# Unzip the dataset downloaded from kaggle
with ZipFile('plantvillage-dataset.zip', 'r') as zipObj:
  zipObj.extractall()

# Test
!ls

# For the disease classification we will use the color dataset as it is logically important and relevant for disease detection
print(os.listdir("plantvillage dataset"))

data = os.listdir("plantvillage dataset")
for i in data:
  print(len(i))

"""Data Explanation:
The Data set includes three variants of images: Color, Grayscale, and Segmented. For our predictive model, we will make use of the color dataset. The color dataset include images of specific plants with a visible disease. Our model aims to learn from this set of images and thus be able to predict what disease a specific plant is afflicted with when provided an image.
"""

# Dataset Path
base_path = "plantvillage dataset/color"

image_path = "/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG"

img = mpimg.imread(image_path)
plt.imshow(img)
plt.axis("off")
plt.show()

# you want the images of the training and testing set to be of the same shape
# needs to be uniform
# Note the third value in the shape represents the colour
# 3 -> RGB, no value -> grayscale
print(img.shape)
print(img) # This will give us an array of pixel data of the image - RGB from 0 - 255

# Image params
img_size = 224
batch_size = 32

"""## Train Test Split"""

# Image Data Generators
# The train_gen and validation_gen handles the entire train-test split for us!

# 0.2 validation means using 20% of the data for validation
data_gen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Train Generator
train_gen = data_gen.flow_from_directory(
    base_path,
    target_size=(img_size, img_size), # Resized image to 224
    batch_size=batch_size, # Each batch has 32 images, can be larger if more compute power -> memory intensive
    subset='training', # training data - 80% flowing into train_gen -> rest is in validation_gen
    class_mode='categorical'
)

# Its split the images across each class (folder in the color directory)

# Validation Generator
validation_gen = data_gen.flow_from_directory(
    base_path,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    subset='validation',
    class_mode='categorical'
)

"""## Convolutional Neural Network (CNN)

### Define the Model
"""

# Define the model
model = models.Sequential()

# Sequential - used when we have a linear stack of layers
# Each layers accepts a tensor and then outputs a tensor
# Conv2D is the 2 dimensional convolutional layer with a 32 kernel, (3, 3) matrix

# First Layer
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))
model.add(layers.MaxPooling2D((2, 2)))

# Second Layer
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))

# Purpose of flattening is to be able to pass into Dense layer which requires 1D
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(train_gen.num_classes, activation='softmax')) # Top/output layer -> predicts class

# Softmax is good for multiclass, if the data was binary I'd probably use sigmoid
# 38 neurons in output layer, each one having a value equal to the probability that it is the class

"""### Model Summary"""

model.summary()

"""### Compiling and Training the Model



"""

# Select your optimizer, loss function and metric
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Training the model

history = model.fit(
    train_gen,
    steps_per_epoch=train_gen.samples // batch_size, # number of steps per each epoch
    epochs=5, # number of epochs
    validation_data=validation_gen, # validation data
    validation_steps=validation_gen.samples // batch_size # number of steps in validation
)

"""### Model Evaluation"""

val_loss, val_accuracy = model.evaluate(validation_gen)
print(f"Validation Accuracy: {val_accuracy}")
print(f"Validation Loss: {val_loss}")

"""### Plot Training and Validation + Loss Accuracy Values"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title("Model Accuracy")
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title("Model Loss")
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# The weird dips at 2 and 4 are because that specific epoch failed to train
# With this error: Your input ran out of data; interrupting training.
# Will Fix and retrain

"""### Process Image"""

def load_and_preprocess_image(image_path, target_size=(224, 224)):
    image = Image.open(image_path)
    image = image.resize(target_size)
    image_array = np.array(image)
    image_array = np.expand_dims(image_array, axis=0)
    image_array = image_array.astype("float32") / 255.0
    return image_array

def predict_disease(model, image_path, class_indices):
    preprocessed_img = load_and_preprocess_image(image_path)
    prediction = model.predict(preprocessed_img)
    predicted_class_index = np.argmax(prediction, axis=1)[0]
    predicted_class_name = class_indices[predicted_class_index]
    return predicted_class_name

# map the class indices to the class names
class_indices = {v: k for k, v in train_gen.class_indices.items()}
class_indices

# Save the class names as a json file
json.dump(class_indices, open("class_indices.json", "w"))

"""## Testing with an Example!"""

image_paths = ["/content/test_apple_black_rot.JPG", "/content/test_blueberry_healthy.jpg", "/content/test_potato_early_blight.jpg"]

predicted_class = []

for image in image_paths:
  predicted_class.append(predict_disease(model, image, class_indices))

# CORRECT EVERY TIME!
predicted_class

"""# Save the Model"""

model.save('drive/MyDrive/plant_disease_predictor.keras')